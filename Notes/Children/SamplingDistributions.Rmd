
Sampling Distributions (Chapter 4)
========================================================

Toss a fair coin $n = 10$ times and note the proportion of heads $\hat{p}$.  If you repeat the experiment, you probably would not get the same proportion of heads.  If you toss 50 sets of 10 coin flips, you might see outcomes (i.e., proportions of heads, $\hat{p}$) such as those below.

```{r sampDIST}
set.seed(12)
cointoss <- rbinom(50, 10, 1/2)
phat <- cointoss/10
xtabs(~phat)
plot(xtabs(~phat),ylab= "count",xlab = expression(hat(p)))
```
Although proportions between 0.3 and 0.7 occur most often, we see there is a proportion as low as 0.1 heads and as high as 0.8 heads.  Instead of 50 sets of 10 coin flips, the next simulation performs 50,000 sets of 10 tosses.

```{r sampDISTsim}
set.seed(12)
cointoss <- rbinom(50000, 10, 1/2)
phat <- cointoss/10
xtabs(~phat)
mean(phat)
sd(phat)
plot(xtabs(~phat),ylab= "count",xlab = expression(hat(p)))
```

The previous plot is an approximation to the *sampling distribution of $\hat{p}$*.  The mean of the sampling distribution of $\hat{p}$ is $\mu_{\hat{p}} = p$, and the standard deviation of the sampling distribution of $\hat{p}$, $\sigma_{\hat{p}} = \sqrt{p\times(1-p)/n}$.  The standard deviation of the simulated $\hat{p}$ values, the standard deviation of a statistic, is called a *standard error*.  In this simulation, the estimated mean of the statistic is written as $\hat{\mu}_{\hat{p}}=$ `r mean(phat)`. The standard error of $\hat{p}$, sometimes written as $SE(\hat{p})$ or $\hat{\sigma}_{\hat{p}}$ is `r sd(phat)`.

## The Central Limit Theorem

Let $X_1, X_2,...,X_n$ be independent identically distributed random variables with mean $\mu$ and variance $\sigma^2$, both finite.  Then for any constant z,

$$\lim_{n \to \infty} P\left(\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \leq z \right) = \Phi(z) $$

Where $\Phi$ is the cdf of the standard normal distribution.  The central limit theorem means that for ``sufficiently large'' $n$, the sampling distribution of $\bar{X}$ is approximately normal with mean $\mu_{\bar{X}}= \mu$, and standard deviation $\sigma_{\bar{X}} = \sigma/\sqrt{n}$.  Recall that the standard deviation of a statistic is called a standard error.  Consequently, our text refers to $\sigma_{\bar{X}}$ as $SE(\bar{X})$.

#### Note:  If you one is sampling from a normal distribution, then the resulting sampling distribution of the sample mean is exactly normal.  It is always the case that $\mu_{\bar{X}} = \mu$ and $\sigma_{\bar{X}} = \sigma/\sqrt{n}$ regardless of the population one is sampling from.

## Just how large is ''sufficiently large''?

Consider the following simulations

```{r CLTsim, fig.height = 12, fig.width= 9}
set.seed(123)
par(mfrow=c(4,3))
# X~N(50,15)
x <- seq(0,100,.01)
y <- dnorm(x,50,15)
plot(x,y,type="l",col="blue",lwd=2,main="X~N(50,15)",xlab="",ylab="")

# X~U(0,1)
x <- seq(0,1,.001)
y <- dunif(x,0,1)
plot(x,y,type="l",col="blue",lwd=2,main="X~U(0,1)",xlab="",ylab="")

# X~Exp(1)
x <- seq(0,5,.01)
y <- dexp(x,1)
plot(x,y,type="l",col="blue",lwd=2,main="X~Exp(1)",xlab="",ylab="")

m <- 20000  # Number of Samples
EX <- 1.2   # Character expansion

xbar.5 <- apply(matrix(rnorm(m*5,50,15),nrow=m),1,mean)
hist(xbar.5,breaks="Scott",col="blue",xlim=c(0,100),prob=T,xlab="",ylab="",main="")
mtext(  expression(bar(x)[5]),side=3,line=1,cex=EX)

xbar.5 <- apply(matrix(runif(m*5,0,1),nrow=m),1,mean)
hist(xbar.5,breaks="Scott",col="blue",xlim=c(0,1),prob=T,xlab="",ylab="",main="")
mtext(  expression(bar(x)[5]),side=3,line=1,cex=EX)

xbar.5 <- apply(matrix(rexp(m*5,1),nrow=m),1,mean)
hist(xbar.5,breaks="Scott",col="blue",xlim=c(0,5),prob=T,xlab="",ylab="",main="")
mtext(  expression(bar(x)[5]),side=3,line=1,cex=EX)

xbar.10 <- apply(matrix(rnorm(m*10,50,15),nrow=m),1,mean)
hist(xbar.10,breaks="Scott",col="blue",xlim=c(0,100),prob=T,xlab="",ylab="",main="")
mtext(  expression(bar(x)[10]),side=3,line=1,cex=EX)

xbar.10 <- apply(matrix(runif(m*10,0,1),nrow=m),1,mean)
hist(xbar.10,breaks="Scott",col="blue",xlim=c(0,1),prob=T,xlab="",ylab="",main="")
mtext(  expression(bar(x)[10]),side=3,line=1,cex=EX)

xbar.10 <- apply(matrix(rexp(m*10,1),nrow=m),1,mean)
hist(xbar.10,breaks="Scott",col="blue",xlim=c(0,5),prob=T,xlab="",ylab="",main="")
mtext(  expression(bar(x)[10]),side=3,line=1,cex=EX)

xbar.30 <- apply(matrix(rnorm(m*30,50,15),nrow=m),1,mean)
hist(xbar.30,breaks="Scott",col="blue",xlim=c(0,100),prob=T,xlab="",ylab="",main="")
mtext(  expression(bar(x)[30]),side=3,line=1,cex=EX)

xbar.30 <- apply(matrix(runif(m*30,0,1),nrow=m),1,mean)
hist(xbar.30,breaks="Scott",col="blue",xlim=c(0,1),prob=T,xlab="",ylab="",main="")
mtext(  expression(bar(x)[30]),side=3,line=1,cex=EX)

xbar.30 <- apply(matrix(rexp(m*30,1),nrow=m),1,mean)
hist(xbar.30,breaks="Scott",col="blue",xlim=c(0,5),prob=T,xlab="",ylab="",main="")
mtext(  expression(bar(x)[30]),side=3,line=1,cex=EX)

par(mfrow=c(1,1))
```

#### Note:  The usual rule of thumb, found in most textbooks, is that the CLT is reasonably accurate if $n \geq 30$.  Such rules are wishful thinking, dating to a pre-computer age when one had few realistic alternatives to using the CLT because most other methods were computationally infeasible.


## CLT for Binomial Data

**Example 4.9** Toss a fair coin 300 times.  Find the approximate probability of getting at most 160 heads.

**Solution:** Let $X=$ the number of heads in 300 flips of a fair coin.  Since $X \sim Bin(n = 300, p = 1/2)$ it follows that $\mu_X = np$ and $\sigma_{X} =\sqrt{np\times(1 - p)}$, and $Y \dot{\sim} N(np, \sqrt{np\times(1 - p)})$.  It follows that $P(X <= 160) = P\left(\frac{X - np}{\sqrt{np \times (1 - p)}} = Z \leq \frac{160 - 150}{\sqrt{300/4}}\right).$  Furthermore, $P(Z \leq 1.154701)=$ `r pnorm((160-150)/sqrt(300/4))`.  Solve the problem in class using $\hat{p}$ as the random variable.

**Exact Solution:** $P(X \leq 160)= \sum_{x = 0}^{x = 160}\binom{300}{x} 0.5^x 0.5^{300-x}=$ `r pbinom(160, 300, 1/2)`.
